{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n# Predict TripAdvisor Rating\n## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor\n**По ходу задачи:**\n* Прокачаем работу с pandas\n* Научимся работать с Kaggle Notebooks\n* Поймем как делать предобработку различных данных\n* Научимся работать с пропущенными данными (Nan)\n* Познакомимся с различными видами кодирования признаков\n* Немного попробуем [Feature Engineering](https://ru.wikipedia.org/wiki/Конструирование_признаков) (генерировать новые признаки)\n* И совсем немного затронем ML\n* И многое другое...   ","metadata":{}},{"cell_type":"markdown","source":"# import","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import StandardScaler\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\nimport math\n\nimport time\nfrom datetime import datetime\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-08-30T14:03:25.873881Z","iopub.execute_input":"2021-08-30T14:03:25.874237Z","iopub.status.idle":"2021-08-30T14:03:25.889918Z","shell.execute_reply.started":"2021-08-30T14:03:25.874179Z","shell.execute_reply":"2021-08-30T14:03:25.889159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:03:27.825857Z","iopub.execute_input":"2021-08-30T14:03:27.826232Z","iopub.status.idle":"2021-08-30T14:03:27.830885Z","shell.execute_reply.started":"2021-08-30T14:03:27.82617Z","shell.execute_reply":"2021-08-30T14:03:27.829467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:03:30.341058Z","iopub.execute_input":"2021-08-30T14:03:30.341705Z","iopub.status.idle":"2021-08-30T14:03:32.878126Z","shell.execute_reply.started":"2021-08-30T14:03:30.341608Z","shell.execute_reply":"2021-08-30T14:03:32.876967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATA","metadata":{}},{"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-08-30T14:30:04.55581Z","iopub.execute_input":"2021-08-30T14:30:04.556248Z","iopub.status.idle":"2021-08-30T14:30:04.844028Z","shell.execute_reply.started":"2021-08-30T14:30:04.556206Z","shell.execute_reply":"2021-08-30T14:30:04.843282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:06.183051Z","iopub.execute_input":"2021-08-30T14:30:06.183507Z","iopub.status.idle":"2021-08-30T14:30:06.22577Z","shell.execute_reply.started":"2021-08-30T14:30:06.183462Z","shell.execute_reply":"2021-08-30T14:30:06.223896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:08.775914Z","iopub.execute_input":"2021-08-30T14:30:08.776237Z","iopub.status.idle":"2021-08-30T14:30:08.794286Z","shell.execute_reply.started":"2021-08-30T14:30:08.776179Z","shell.execute_reply":"2021-08-30T14:30:08.793647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:10.801141Z","iopub.execute_input":"2021-08-30T14:30:10.80161Z","iopub.status.idle":"2021-08-30T14:30:10.82392Z","shell.execute_reply.started":"2021-08-30T14:30:10.801559Z","shell.execute_reply":"2021-08-30T14:30:10.823001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:12.555626Z","iopub.execute_input":"2021-08-30T14:30:12.55599Z","iopub.status.idle":"2021-08-30T14:30:12.575615Z","shell.execute_reply.started":"2021-08-30T14:30:12.55593Z","shell.execute_reply":"2021-08-30T14:30:12.574281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:14.586835Z","iopub.execute_input":"2021-08-30T14:30:14.587228Z","iopub.status.idle":"2021-08-30T14:30:14.598671Z","shell.execute_reply.started":"2021-08-30T14:30:14.587169Z","shell.execute_reply":"2021-08-30T14:30:14.597599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:17.227306Z","iopub.execute_input":"2021-08-30T14:30:17.227833Z","iopub.status.idle":"2021-08-30T14:30:17.238298Z","shell.execute_reply.started":"2021-08-30T14:30:17.227593Z","shell.execute_reply":"2021-08-30T14:30:17.237312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Для корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:20.029333Z","iopub.execute_input":"2021-08-30T14:30:20.029771Z","iopub.status.idle":"2021-08-30T14:30:20.070423Z","shell.execute_reply.started":"2021-08-30T14:30:20.029728Z","shell.execute_reply":"2021-08-30T14:30:20.069646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:22.232384Z","iopub.execute_input":"2021-08-30T14:30:22.232887Z","iopub.status.idle":"2021-08-30T14:30:22.276673Z","shell.execute_reply.started":"2021-08-30T14:30:22.232836Z","shell.execute_reply":"2021-08-30T14:30:22.275476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Подробнее по признакам:\n* City: Город \n* Cuisine Style: Кухня\n* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n* Price Range: Цены в ресторане в 3 категориях\n* Number of Reviews: Количество отзывов\n* Reviews: 2 последних отзыва и даты этих отзывов\n* URL_TA: страница ресторана на 'www.tripadvisor.com' \n* ID_TA: ID ресторана в TripAdvisor\n* Rating: Рейтинг ресторана","metadata":{}},{"cell_type":"code","source":"data.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:24.619953Z","iopub.execute_input":"2021-08-30T14:30:24.620264Z","iopub.status.idle":"2021-08-30T14:30:24.642072Z","shell.execute_reply.started":"2021-08-30T14:30:24.620216Z","shell.execute_reply":"2021-08-30T14:30:24.640819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Reviews[1]","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:26.607323Z","iopub.execute_input":"2021-08-30T14:30:26.607648Z","iopub.status.idle":"2021-08-30T14:30:26.615834Z","shell.execute_reply.started":"2021-08-30T14:30:26.607585Z","shell.execute_reply":"2021-08-30T14:30:26.614525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Как видим, большинство признаков у нас требует очистки и предварительной обработки.","metadata":{}},{"cell_type":"markdown","source":"# Cleaning and Prepping Data\nОбычно данные содержат в себе кучу мусора, который необходимо почистить, для того чтобы привести их в приемлемый формат. Чистка данных — это необходимый этап решения почти любой реальной задачи.   ","metadata":{}},{"cell_type":"markdown","source":"## 1. Обработка NAN \nУ наличия пропусков могут быть разные причины, но пропуски нужно либо заполнить, либо исключить из набора полностью. Но с пропусками нужно быть внимательным, **даже отсутствие информации может быть важным признаком!**   \nПо этому перед обработкой NAN лучше вынести информацию о наличии пропуска как отдельный признак ","metadata":{}},{"cell_type":"code","source":"# Для примера я возьму столбец Number of Reviews\ndata['Number_of_Reviews_isNAN'] = pd.isna(data['Number of Reviews']).astype('uint8')\n# сделаем то же для других столбцов\ndata['Cuisine_Style_isNAN']= pd.isna(data['Cuisine Style']).astype('uint8')\ndata['Price Range_isNAN']= pd.isna(data['Price Range']).astype('uint8')","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:33.522559Z","iopub.execute_input":"2021-08-30T14:30:33.522873Z","iopub.status.idle":"2021-08-30T14:30:33.542909Z","shell.execute_reply.started":"2021-08-30T14:30:33.522824Z","shell.execute_reply":"2021-08-30T14:30:33.542032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Number_of_Reviews_isNAN'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:35.110677Z","iopub.execute_input":"2021-08-30T14:30:35.111115Z","iopub.status.idle":"2021-08-30T14:30:35.120447Z","shell.execute_reply.started":"2021-08-30T14:30:35.111072Z","shell.execute_reply":"2021-08-30T14:30:35.119538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Далее заполняем пропуски средним значением по городу:\n\ncities = list(data['City'].unique())\nmean_NoR_citi = {}\nfor n in cities:\n    if n in mean_NoR_citi:\n        continue\n    else:\n        mean_NoR_citi[n] = data[data['City'] == n]['Number of Reviews'].mean()\n        \nright_views = []\nfor n,m in zip(data['City'], data['Number of Reviews']):\n    if math.isnan(m):\n        right_views.append(mean_NoR_citi[n])\n    else:\n        right_views.append(m)\n\ndata['Number of Reviews'] = right_views","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:40.405226Z","iopub.execute_input":"2021-08-30T14:30:40.405577Z","iopub.status.idle":"2021-08-30T14:30:40.765946Z","shell.execute_reply.started":"2021-08-30T14:30:40.405515Z","shell.execute_reply":"2021-08-30T14:30:40.764927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Пропуски в столбце Cuisine Style заполним строкой ","metadata":{}},{"cell_type":"code","source":"#пропуски в столбце Cuisine Style заполним строкой, т.к. будем позже считать кол-во кухонь\ndata['Cuisine Style'].fillna('unknown', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:43.224924Z","iopub.execute_input":"2021-08-30T14:30:43.225359Z","iopub.status.idle":"2021-08-30T14:30:43.237245Z","shell.execute_reply.started":"2021-08-30T14:30:43.225318Z","shell.execute_reply":"2021-08-30T14:30:43.236399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Обработка признаков\nДля начала посмотрим какие признаки у нас могут быть категориальными.","metadata":{}},{"cell_type":"code","source":"data.nunique(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:46.063143Z","iopub.execute_input":"2021-08-30T14:30:46.063652Z","iopub.status.idle":"2021-08-30T14:30:46.210413Z","shell.execute_reply.started":"2021-08-30T14:30:46.063414Z","shell.execute_reply":"2021-08-30T14:30:46.209298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Какие признаки можно считать категориальными?","metadata":{}},{"cell_type":"markdown","source":"Для кодирования категориальных признаков есть множество подходов:\n* Label Encoding\n* One-Hot Encoding\n* Target Encoding\n* Hashing\n\nВыбор кодирования зависит от признака и выбраной модели.\nНе будем сейчас сильно погружаться в эту тематику, давайте посмотрим лучше пример с One-Hot Encoding:\n![](https://i.imgur.com/mtimFxh.png)","metadata":{}},{"cell_type":"code","source":"data.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:49.062391Z","iopub.execute_input":"2021-08-30T14:30:49.062721Z","iopub.status.idle":"2021-08-30T14:30:49.083775Z","shell.execute_reply.started":"2021-08-30T14:30:49.062664Z","shell.execute_reply":"2021-08-30T14:30:49.082927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:51.703867Z","iopub.execute_input":"2021-08-30T14:30:51.704218Z","iopub.status.idle":"2021-08-30T14:30:51.728052Z","shell.execute_reply.started":"2021-08-30T14:30:51.704156Z","shell.execute_reply":"2021-08-30T14:30:51.727074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Возьмем следующий признак \"Price Range\".","metadata":{}},{"cell_type":"code","source":"data['Price Range'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:55.056764Z","iopub.execute_input":"2021-08-30T14:30:55.057063Z","iopub.status.idle":"2021-08-30T14:30:55.075912Z","shell.execute_reply.started":"2021-08-30T14:30:55.057017Z","shell.execute_reply":"2021-08-30T14:30:55.075147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"values = {'$$$$': 3, '$' : 1, '$$ - $$$': 2, np.nan: np.nan}\ndata['Price Range'] = data['Price Range'].apply(lambda x: values[x])","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:57.823615Z","iopub.execute_input":"2021-08-30T14:30:57.824098Z","iopub.status.idle":"2021-08-30T14:30:57.860422Z","shell.execute_reply.started":"2021-08-30T14:30:57.824051Z","shell.execute_reply":"2021-08-30T14:30:57.859408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Price Range'].fillna(data['Price Range'].mean(), inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:30:59.814387Z","iopub.execute_input":"2021-08-30T14:30:59.814728Z","iopub.status.idle":"2021-08-30T14:30:59.821416Z","shell.execute_reply.started":"2021-08-30T14:30:59.814668Z","shell.execute_reply":"2021-08-30T14:30:59.820619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Price Range'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:31:01.911761Z","iopub.execute_input":"2021-08-30T14:31:01.912284Z","iopub.status.idle":"2021-08-30T14:31:01.92175Z","shell.execute_reply.started":"2021-08-30T14:31:01.912235Z","shell.execute_reply":"2021-08-30T14:31:01.920529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# столбец City нам понадобится, поэтому преобразуем его позже\n#data = pd.get_dummies(data, columns=[ 'City','Price Range'], dummy_na=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Для некоторых алгоритмов МЛ даже для не категориальных признаков можно применить One-Hot Encoding, и это может улучшить качество модели. Пробуйте разные подходы к кодированию признака - никто не знает заранее, что может взлететь.","metadata":{}},{"cell_type":"markdown","source":"### Обработать другие признаки вы должны самостоятельно!\nДля обработки других признаков вам возможно придется даже написать свою функцию, а может даже и не одну, но в этом и есть ваша практика в этом модуле!     \nСледуя подсказкам в модуле вы сможете более подробно узнать, как сделать эти приобразования.","metadata":{}},{"cell_type":"code","source":"#посчитаем, сколько представлено кухонь, добавим признак\ndata['Cuisine Style'] = data['Cuisine Style'].apply(\n    lambda x: str(x).replace('[', '').replace(']', '').replace(\"'\", '').replace(' ', '').replace('\"', ''))\ndata['Cuisine Style'] = data['Cuisine Style'].apply(lambda x: x.split(','))\ndata['Number_of_kitchen'] = data['Cuisine Style'].apply(lambda x: len(x))","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:31:11.938207Z","iopub.execute_input":"2021-08-30T14:31:11.938536Z","iopub.status.idle":"2021-08-30T14:31:12.351062Z","shell.execute_reply.started":"2021-08-30T14:31:11.938484Z","shell.execute_reply":"2021-08-30T14:31:12.349181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Добавим стобцы для кухонь и создадим для этого отдельный датасет\ncuisines = []\nfor n in data['Cuisine Style']:\n    if type(n) == float:\n        continue\n    else:\n        for m in n:\n            cuisines.append(m)\n            \ncuisine_set = set(cuisines)\n\ndf_cuisines = pd.DataFrame()\ndef find_item(cell):\n    if item in cell:\n        return 1\n    return 0\nfor item in cuisine_set:\n    df_cuisines[item] = data['Cuisine Style'].apply(find_item)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:31:18.260233Z","iopub.execute_input":"2021-08-30T14:31:18.26076Z","iopub.status.idle":"2021-08-30T14:31:22.763588Z","shell.execute_reply.started":"2021-08-30T14:31:18.260707Z","shell.execute_reply":"2021-08-30T14:31:22.762473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Добавим столбцы для городов, создадим отдельный датафрейм для него, а объединим позже\ncity_list = []\nfor n in data['City']:\n    city_list.append(n)\ncities = set(city_list)\n\ndf_cities = pd.DataFrame()\ndef find_item(cell):\n    if item in cell:\n        return 1\n    return 0\nfor item in cities:\n    df_cities[item] = data['City'].apply(find_item)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:36:39.983501Z","iopub.execute_input":"2021-08-30T14:36:39.9839Z","iopub.status.idle":"2021-08-30T14:36:40.948658Z","shell.execute_reply.started":"2021-08-30T14:36:39.983823Z","shell.execute_reply":"2021-08-30T14:36:40.947903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Reviews']","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:36:42.724903Z","iopub.execute_input":"2021-08-30T14:36:42.725345Z","iopub.status.idle":"2021-08-30T14:36:42.734447Z","shell.execute_reply.started":"2021-08-30T14:36:42.725273Z","shell.execute_reply":"2021-08-30T14:36:42.733614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Займемся датами отзывов. Значения даты представлены в формате str, переведем в формат float с помощью библиотеки datetime\n# Переведем сначала их в формат YYYY/MM/DD, а затем в формат float. На этом шаге найдем среднее значение дат, \n# среднее значение времени между отзывами (mean_date_gap), максимальное значение между отзывами(max_date_gap):\nreviews = data['Reviews']\ndates = []\ndate_gap = []\nfor n in reviews:\n    if type(n) != float:\n        tmp_review = n.split('], [')\n        tmp_date = tmp_review[1].replace(\"'\", \"\").replace(']]', \"\").split(', ')\n        if len(tmp_date) == 2:\n            date_1 = tmp_date[0][6:10] + '/' + tmp_date[0][0:2] + '/' + tmp_date[0][3:5]\n            date_1 = datetime.strptime(date_1, '%Y/%m/%d').timestamp()\n            date_2 = tmp_date[1][6:10] + '/' + tmp_date[1][0:2] + '/' + tmp_date[1][3:5]\n            date_2 = datetime.strptime(date_2, '%Y/%m/%d').timestamp()\n            dates.append(date_1)\n            date_gap.append(abs(date_1 - date_2))\n            dates.append(date_2)\n        elif len(tmp_date) == 1:\n            if len(tmp_date[0]) > 0:\n                date_1 = tmp_date[0][6:10] + '/' + tmp_date[0][0:2] + '/' + tmp_date[0][3:5]\n                date_1 = datetime.strptime(date_1, '%Y/%m/%d').timestamp()\n                dates.append(date_1)\n            else:\n                continue\n    \nmean_date = sum(dates) / len(dates)\nmax_date_gap = max(date_gap)\nmean_date_gap = sum(date_gap) /len(date_gap)\n\n# Повторим код, но уже заменяя нули средним значением:\n\nreviews = data['Reviews']\ndates = []\ndate_gap = []\nfor n in reviews:\n    if type(n) != float:\n        tmp_review = n.split('], [')\n        tmp_date = tmp_review[1].replace(\"'\", \"\").replace(']]', \"\").split(', ')\n        if len(tmp_date) == 2:\n            date_1 = tmp_date[0][6:10] + '/' + tmp_date[0][0:2] + '/' + tmp_date[0][3:5]\n            date_1 = datetime.strptime(date_1, '%Y/%m/%d').timestamp()\n            date_2 = tmp_date[1][6:10] + '/' + tmp_date[1][0:2] + '/' + tmp_date[1][3:5]\n            date_2 = datetime.strptime(date_2, '%Y/%m/%d').timestamp()\n            if date_1 > date_2:\n                dates.append(date_1)\n                date_gap.append(date_1 - date_2)\n            else:\n                dates.append(date_2)\n                date_gap.append(date_2 - date_1)\n        elif len(tmp_date) == 1:\n            if len(tmp_date[0]) > 0:\n                date_1 = tmp_date[0][6:10] + '/' + tmp_date[0][0:2] + '/' + tmp_date[0][3:5]\n                date_1 = datetime.strptime(date_1, '%Y/%m/%d').timestamp()\n                dates.append(date_1)\n            else:\n                dates.append(mean_date)\n            date_gap.append(max_date_gap)\n    else:\n        dates.append(mean_date)\n        date_gap.append(mean_date_gap)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:36:47.601365Z","iopub.execute_input":"2021-08-30T14:36:47.601867Z","iopub.status.idle":"2021-08-30T14:36:50.530912Z","shell.execute_reply.started":"2021-08-30T14:36:47.601808Z","shell.execute_reply":"2021-08-30T14:36:50.530222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# если даты две, то используем только свежую дату, чтобы совпало кол-во строк в датафрейме. Добавляем столбцы:\ndata['Last review date'] = dates\ndata['Date_gap'] = date_gap","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:37:01.082025Z","iopub.execute_input":"2021-08-30T14:37:01.082348Z","iopub.status.idle":"2021-08-30T14:37:01.109148Z","shell.execute_reply.started":"2021-08-30T14:37:01.082299Z","shell.execute_reply":"2021-08-30T14:37:01.108172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#является ли ресторан сетевым\nnet_rest = dict(data['Restaurant_id'].value_counts())\nfor x,y in net_rest.items():\n    if y==1:\n        net_rest[x]=0\n    else:\n        net_rest[x]=1\ndata['net_rest']=data['Restaurant_id'].map(net_rest)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:37:10.031997Z","iopub.execute_input":"2021-08-30T14:37:10.032344Z","iopub.status.idle":"2021-08-30T14:37:10.282143Z","shell.execute_reply.started":"2021-08-30T14:37:10.032291Z","shell.execute_reply":"2021-08-30T14:37:10.281041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['net_rest'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:37:12.510623Z","iopub.execute_input":"2021-08-30T14:37:12.510987Z","iopub.status.idle":"2021-08-30T14:37:12.521097Z","shell.execute_reply.started":"2021-08-30T14:37:12.510893Z","shell.execute_reply":"2021-08-30T14:37:12.519938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Находится ли ресторан в столице?\ncapitals = [\n        'London', 'Paris', 'Madrid', 'Berlin', 'Rome', 'Prague', 'Lisbon',\n        'Vienna', 'Amsterdam', 'Brussels', 'Stockholm', 'Budapest', 'Warsaw',\n        'Dublin', 'Copenhagen', 'Athens', 'Oslo', 'Helsinki', 'Bratislava',\n        'Luxembourg', 'Ljubljana', 'Edinburgh']\ndata['Capital'] = data['City'].apply(lambda x: 1 if x in capitals else 0)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:37:15.532295Z","iopub.execute_input":"2021-08-30T14:37:15.532649Z","iopub.status.idle":"2021-08-30T14:37:15.581221Z","shell.execute_reply.started":"2021-08-30T14:37:15.532574Z","shell.execute_reply":"2021-08-30T14:37:15.580374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Добавим население городов\n    population = {\n        'Paris': 2190327,\n        'Stockholm': 961609,\n        'London': 8908081,\n        'Berlin': 3644826,\n        'Munich': 1456039,\n        'Oporto': 237591,\n        'Milan': 1378689,\n        'Bratislava': 432864,\n        'Vienna': 1821582,\n        'Rome': 4355725,\n        'Barcelona': 1620343,\n        'Madrid': 3223334,\n        'Dublin': 1173179,\n        'Brussels': 179277,\n        'Zurich': 428737,\n        'Warsaw': 1758143,\n        'Budapest': 1752286,\n        'Copenhagen': 615993,\n        'Amsterdam': 857713,\n        'Lyon': 506615,\n        'Hamburg': 1841179,\n        'Lisbon': 505526,\n        'Prague': 1301132,\n        'Oslo': 673469,\n        'Helsinki': 643272,\n        'Edinburgh': 488100,\n        'Geneva': 200548,\n        'Ljubljana': 284355,\n        'Athens': 664046,\n        'Luxembourg': 115227,\n        'Krakow': 769498\n    }\n\n    data['Population'] = data['City'].map(population)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:37:19.360799Z","iopub.execute_input":"2021-08-30T14:37:19.361139Z","iopub.status.idle":"2021-08-30T14:37:19.380867Z","shell.execute_reply.started":"2021-08-30T14:37:19.361073Z","shell.execute_reply":"2021-08-30T14:37:19.379552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создадим новый столбец с количеством кухонь в разрезе городов и ресторанов\ndata['Cuisine_in_Restaurant_City'] = data['Cuisine Style'].apply(lambda x: len(str(x).split(', ')))\n\n# Выделим в отдельную таблицу для удобства и посчитаем\n# Количество ресторанов в каждом городе, количество кухонь в каждом городе\ntmp_data = data[['City','Restaurant_id','Cuisine Style']].copy() \ntmp_data['Cuisine Style'] = tmp_data['Cuisine Style'].str.split(', ') \ntmp_data = tmp_data.explode('Cuisine Style')\ntmp_data = tmp_data.copy()\ntmp_data.sample(5)\n\n# Группировка и расчет количества ресторанов в каждом городе, количество кухонь в каждом городе\ntmp_data = tmp_data.groupby(['City'])[['Restaurant_id','Cuisine Style']].nunique()\ntmp_data = tmp_data.reset_index()\ntmp_data.columns = ['City','Restaurant_in_City','Cuisine_in_City']\ntmp_data.sample(5)\n\ndata = data.merge(tmp_data, on = 'City')","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:41:24.141608Z","iopub.execute_input":"2021-08-30T14:41:24.142031Z","iopub.status.idle":"2021-08-30T14:41:24.518792Z","shell.execute_reply.started":"2021-08-30T14:41:24.141967Z","shell.execute_reply":"2021-08-30T14:41:24.518023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA \n[Exploratory Data Analysis](https://ru.wikipedia.org/wiki/Разведочный_анализ_данных) - Анализ данных\nНа этом этапе мы строим графики, ищем закономерности, аномалии, выбросы или связи между признаками.\nВ общем цель этого этапа понять, что эти данные могут нам дать и как признаки могут быть взаимосвязаны между собой.\nПонимание изначальных признаков позволит сгенерировать новые, более сильные и, тем самым, сделать нашу модель лучше.\n![](https://miro.medium.com/max/2598/1*RXdMb7Uk6mGqWqPguHULaQ.png)","metadata":{}},{"cell_type":"markdown","source":"### Посмотрим распределение признака","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,7)\ndf_train['Ranking'].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:41:45.041735Z","iopub.execute_input":"2021-08-30T14:41:45.042257Z","iopub.status.idle":"2021-08-30T14:41:45.529379Z","shell.execute_reply.started":"2021-08-30T14:41:45.042212Z","shell.execute_reply":"2021-08-30T14:41:45.528757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"У нас много ресторанов, которые не дотягивают и до 2500 места в своем городе, а что там по городам?","metadata":{}},{"cell_type":"code","source":"df_train['City'].value_counts(ascending=True).plot(kind='barh')","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:41:49.466596Z","iopub.execute_input":"2021-08-30T14:41:49.46692Z","iopub.status.idle":"2021-08-30T14:41:49.953037Z","shell.execute_reply.started":"2021-08-30T14:41:49.466869Z","shell.execute_reply":"2021-08-30T14:41:49.951852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"А кто-то говорил, что французы любят поесть=) Посмотрим, как изменится распределение в большом городе:","metadata":{}},{"cell_type":"code","source":"df_train['Ranking'][df_train['City'] =='London'].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:41:52.970324Z","iopub.execute_input":"2021-08-30T14:41:52.970752Z","iopub.status.idle":"2021-08-30T14:41:53.507154Z","shell.execute_reply.started":"2021-08-30T14:41:52.970708Z","shell.execute_reply":"2021-08-30T14:41:53.506153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# посмотрим на топ 10 городов\nfor x in (df_train['City'].value_counts())[0:10].index:\n    df_train['Ranking'][df_train['City'] == x].hist(bins=100)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:41:57.118804Z","iopub.execute_input":"2021-08-30T14:41:57.119302Z","iopub.status.idle":"2021-08-30T14:42:00.030428Z","shell.execute_reply.started":"2021-08-30T14:41:57.119254Z","shell.execute_reply":"2021-08-30T14:42:00.029265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Получается, что Ranking имеет нормальное распределение, просто в больших городах больше ресторанов, из-за мы этого имеем смещение.\n\n>Подумайте как из этого можно сделать признак для вашей модели. Я покажу вам пример, как визуализация помогает находить взаимосвязи. А далее действуйте без подсказок =) \n","metadata":{}},{"cell_type":"code","source":"rest_number = data.groupby('City')['Restaurant_id'].count().reset_index()\nrest_number.sort_values(by= 'Restaurant_id')\nrest_number.rename(columns = {'Restaurant_id':'count_in_city'}, inplace = True)\nrest_number","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:42:08.46608Z","iopub.execute_input":"2021-08-30T14:42:08.466611Z","iopub.status.idle":"2021-08-30T14:42:08.517408Z","shell.execute_reply.started":"2021-08-30T14:42:08.466538Z","shell.execute_reply":"2021-08-30T14:42:08.516322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.merge(rest_number, on='City', how='left',sort=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:42:14.606428Z","iopub.execute_input":"2021-08-30T14:42:14.606771Z","iopub.status.idle":"2021-08-30T14:42:14.661333Z","shell.execute_reply.started":"2021-08-30T14:42:14.606719Z","shell.execute_reply":"2021-08-30T14:42:14.659955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Ranking_norm']= data['Ranking']/data['count_in_city']\ndata['Ranking']= data['Ranking_norm']\ndata.drop(['Ranking_norm'],axis = 1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:42:18.361853Z","iopub.execute_input":"2021-08-30T14:42:18.362242Z","iopub.status.idle":"2021-08-30T14:42:18.406794Z","shell.execute_reply.started":"2021-08-30T14:42:18.362182Z","shell.execute_reply":"2021-08-30T14:42:18.405363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:42:20.955039Z","iopub.execute_input":"2021-08-30T14:42:20.955348Z","iopub.status.idle":"2021-08-30T14:42:20.987781Z","shell.execute_reply.started":"2021-08-30T14:42:20.9553Z","shell.execute_reply":"2021-08-30T14:42:20.987119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# для One-Hot Encoding в pandas есть готовая функция - get_dummies. Особенно радует параметр dummy_na\ndata = pd.get_dummies(data, columns=[ 'City','Price Range'], dummy_na=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:42:50.089835Z","iopub.execute_input":"2021-08-30T14:42:50.09032Z","iopub.status.idle":"2021-08-30T14:42:50.129878Z","shell.execute_reply.started":"2021-08-30T14:42:50.090254Z","shell.execute_reply":"2021-08-30T14:42:50.129082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Посмотрим распределение целевой переменной","metadata":{}},{"cell_type":"code","source":"df_train['Rating'].value_counts(ascending=True).plot(kind='barh')","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:42:52.624932Z","iopub.execute_input":"2021-08-30T14:42:52.625461Z","iopub.status.idle":"2021-08-30T14:42:52.898181Z","shell.execute_reply.started":"2021-08-30T14:42:52.62541Z","shell.execute_reply":"2021-08-30T14:42:52.897499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Посмотрим распределение целевой переменной относительно признака","metadata":{}},{"cell_type":"code","source":"df_train['Ranking'][df_train['Rating'] == 5].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:42:55.223989Z","iopub.execute_input":"2021-08-30T14:42:55.224286Z","iopub.status.idle":"2021-08-30T14:42:55.789Z","shell.execute_reply.started":"2021-08-30T14:42:55.224247Z","shell.execute_reply":"2021-08-30T14:42:55.787823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['Ranking'][df_train['Rating'] < 4].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:42:57.650393Z","iopub.execute_input":"2021-08-30T14:42:57.650719Z","iopub.status.idle":"2021-08-30T14:42:58.18647Z","shell.execute_reply.started":"2021-08-30T14:42:57.650666Z","shell.execute_reply":"2021-08-30T14:42:58.185167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### И один из моих любимых - [корреляция признаков](https://ru.wikipedia.org/wiki/Корреляция)\nНа этом графике уже сейчас вы сможете заметить, как признаки связаны между собой и с целевой переменной.","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15,10)\nsns.heatmap(data.drop(['sample'], axis=1).corr(),)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:43:03.213545Z","iopub.execute_input":"2021-08-30T14:43:03.213892Z","iopub.status.idle":"2021-08-30T14:43:05.824655Z","shell.execute_reply.started":"2021-08-30T14:43:03.213851Z","shell.execute_reply":"2021-08-30T14:43:05.82356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Вообще благодаря визуализации в этом датасете можно узнать много интересных фактов, например:\n* где больше Пицерий в Мадриде или Лондоне?\n* в каком городе кухня ресторанов более разнообразна?\n\nпридумайте свои вопрос и найдите на него ответ в данных)","metadata":{}},{"cell_type":"markdown","source":"# Data Preprocessing\nТеперь, для удобства и воспроизводимости кода, завернем всю обработку в одну большую функцию.","metadata":{}},{"cell_type":"code","source":"# на всякий случай, заново подгружаем данные\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'/kaggle_task.csv')\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T14:47:53.78143Z","iopub.execute_input":"2021-08-30T14:47:53.781761Z","iopub.status.idle":"2021-08-30T14:47:54.117547Z","shell.execute_reply.started":"2021-08-30T14:47:53.781714Z","shell.execute_reply":"2021-08-30T14:47:54.116506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preproc_data(df_input):\n    '''includes several functions to pre-process the predictor data.'''\n    \n    df_output = df_input.copy()\n    \n    # ################### 1. Предобработка ############################################################## \n    # убираем не нужные для модели признаки\n    df_output.drop(['ID_TA',], axis = 1, inplace=True)\n   \n    \n    \n    # ################### 2. NAN ############################################################## \n    # Далее заполняем пропуски, вы можете попробовать заполнением средним или средним по городу и тд...\n    df_output['Number of Reviews'].fillna(0, inplace=True)\n    df_output['Cuisine Style'].fillna(\"['Other']\", inplace=True)\n    \n    values = {'$$$$': 3, '$' : 1, '$$ - $$$': 2, np.nan: np.nan}\n    df_output['Price Range'] = df_output['Price Range'].apply(lambda x: values[x])\n    df_output['Price Range'].fillna(df_output['Price Range'].mode()[0], inplace=True)\n    \n    #нормализуем признак Ranking,для этого сначала посчитаем кол-во ресторанов в городе\n    rest_number= df_output.groupby('City')['Restaurant_id'].count().reset_index()\n    rest_number.sort_values(by = 'Restaurant_id',ascending=False)\n    rest_number.rename(columns = {'Restaurant_id':'count_in_city'}, inplace = True)\n\n    df_output = df_output.merge(rest_number, on='City', how='left',sort=False)\n    \n    df_output['Ranking_norm']= df_output['Ranking']/df_output['count_in_city']# и найдем отношение Rank к кол-ву ресторанов\n    df_output['Ranking']= df_output['Ranking_norm']\n    df_output.drop(['Ranking_norm'],axis = 1, inplace=True)\n    \n    \n    \n    # ################### 3. Encoding ############################################################## \n    \n    df_output = pd.get_dummies(df_output, columns=[ 'City','Price Range'], dummy_na=True)data['Cuisine Style'].fillna('unknown', inplace=True)\n    \n    \n    # ################### 4. Feature Engineering ####################################################\n    # тут ваш код не генерацию новых фитчей\n    \n    df_output['Cuisine Style'] = df_output['Cuisine Style'].apply(\n    lambda x: str(x).replace('[', '').replace(']', '').replace(\"'\", '').replace(' ', '').replace('\"', ''))\n    df_output['Cuisine Style'] = df_output['Cuisine Style'].apply(lambda x: x.split(','))\n    df_output['Number_of_kitchen'] = df_output['Cuisine Style'].apply(lambda x: len(x))\n    \n    \n    net_rest=dict(data['Restaurant_id'].value_counts())\n\n    for x,y in net_rest.items():\n        if y==1:\n            net_rest[x]=0\n    \n        else:\n            net_rest[x]=1\n    data['net_rest']=data['Restaurant_id'].map(net_rest)        \n    \n    \n    # ################### 5. Clean #################################################### \n    # убираем признаки которые еще не успели обработать, \n    # модель на признаках с dtypes \"object\" обучаться не будет, просто выберим их и удалим\n    object_columns = [s for s in df_output.columns if df_output[s].dtypes == 'object']\n    df_output.drop(object_columns, axis = 1, inplace=True)\n    \n    #хочется попробовать стандартизировать признаки\n    \n    #def StandardScaler_column(df, d_col):\n    #scaler = StandardScaler()\n    #scaler.fit(df[[d_col]])\n    #return scaler.transform(df[[d_col]])\n    \n    return df_output","metadata":{"execution":{"iopub.status.busy":"2021-08-26T22:15:34.217629Z","iopub.execute_input":"2021-08-26T22:15:34.21795Z","iopub.status.idle":"2021-08-26T22:15:34.255986Z","shell.execute_reply.started":"2021-08-26T22:15:34.21791Z","shell.execute_reply":"2021-08-26T22:15:34.255225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_preproc = preproc_data(data)\ndf_preproc.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T22:15:37.115577Z","iopub.execute_input":"2021-08-26T22:15:37.115889Z","iopub.status.idle":"2021-08-26T22:15:37.458742Z","shell.execute_reply.started":"2021-08-26T22:15:37.11584Z","shell.execute_reply":"2021-08-26T22:15:37.457606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">По хорошему, можно было бы перевести эту большую функцию в класс и разбить на подфункции (согласно ООП). ","metadata":{}},{"cell_type":"markdown","source":"#### Запускаем и проверяем что получилось","metadata":{}},{"cell_type":"code","source":"df_preproc = preproc_data(data)\ndf_preproc.sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_preproc.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\ntest_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.Rating.values            # наш таргет\nX = train_data.drop(['Rating'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \nЭто поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**","metadata":{}},{"cell_type":"code","source":"# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# проверяем\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model \nСам ML","metadata":{}},{"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обучаем модель на тестовом наборе данных\nmodel.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission\nЕсли все устраевает - готовим Submission на кагл","metadata":{}},{"cell_type":"code","source":"test_data.sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = test_data.drop(['Rating'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_submission = model.predict(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission['Rating'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# What's next?\nИли что делать, чтоб улучшить результат:\n* Обработать оставшиеся признаки в понятный для машины формат\n* Посмотреть, что еще можно извлечь из признаков\n* Сгенерировать новые признаки\n* Подгрузить дополнительные данные, например: по населению или благосостоянию городов\n* Подобрать состав признаков\n\nВ общем, процесс творческий и весьма увлекательный! Удачи в соревновании!\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}